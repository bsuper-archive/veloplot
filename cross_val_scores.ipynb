{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Random Forests...\n",
      "CTL size: 112 ACT size: 99\n",
      "10-fold CV Acc Mean:  0.923744588745 Scores:  [ 0.90909091  0.95454545  0.95238095  0.95238095  0.9047619   0.95238095\n",
      "  0.9047619   0.9047619   0.95238095  0.85      ]\n",
      "OOB score: 0.938388625592\n",
      "Feature Importances:\n",
      "[('F_mag_kurtosis', 0.0013511503223639398), ('Fy_kurtosis', 0.0017328867901576989), ('Fy_energy', 0.0017339239245113241), ('Fz_skew', 0.0020924388901071376), ('Mz_skew', 0.0023191348668297005), ('My_skew', 0.0024203716983566465), ('Mx_skew', 0.0024535100553970627), ('Fz_max', 0.0025502330229738388), ('Fz_kurtosis', 0.0025507885572875174), ('M_mag_std', 0.0026154957625940376), ('AX_std', 0.0027937119377204004), ('AX_mean', 0.0027986129518747858), ('My_entropy', 0.0028279208425424562), ('AX_min', 0.00293687020791712), ('F_mag_skew', 0.0031782109899028358), ('M_mag_skew', 0.0031946107980664129), ('Fx_std', 0.0032709012695074117), ('Mz_std', 0.0034321907343890113), ('F_mag_std', 0.0037814953524684253), ('My_kurtosis', 0.0037896325295082934), ('Mz_entropy', 0.0040559017002313501), ('Mz_kurtosis', 0.0042165637150573384), ('Fx_kurtosis', 0.0042563902317436769), ('Mz_min', 0.004274747177691632), ('Fy_mean', 0.0043375943552156461), ('Fz_entropy', 0.0045431215246081293), ('Fy_skew', 0.0045674156766782594), ('Fx_skew', 0.0046259794621592272), ('F_mag_max', 0.0049189675531490047), ('AX_kurtosis', 0.0049760085765903576), ('My_mean', 0.0050693219885458432), ('M_mag_kurtosis', 0.0051880327080094423), ('M_mag_max', 0.0052106564784922156), ('Fx_energy', 0.0053603778925515599), ('Fy_max', 0.005647236225034831), ('Fy_min', 0.0057664139700196659), ('M_mag_entropy', 0.0070032895557567976), ('F_mag_energy', 0.0071187639367411562), ('Fy_entropy', 0.0076477698379884265), ('Mx_kurtosis', 0.0083427108668218172), ('Fx_entropy', 0.010154192902767865), ('Mz_energy', 0.010508232289016794), ('Mx_std', 0.010759289721567254), ('Mx_max', 0.011185155602366848), ('Mx_entropy', 0.011290557693314223), ('Fx_max', 0.01155916298646094), ('F_mag_entropy', 0.011714530301690278), ('My_max', 0.011878830709184423), ('Mz_mean', 0.011977064556382375), ('Mz_max', 0.012046143934481095), ('F_mag_mean', 0.01309572659383283), ('My_energy', 0.01386876363321443), ('Fy_std', 0.01423432986991024), ('M_mag_energy', 0.014804603229461937), ('Fz_std', 0.016281229016153326), ('Fx_min', 0.016831693377474984), ('F_mag_min', 0.020075612264931333), ('M_mag_mean', 0.02316951729911489), ('Fz_min', 0.024919049118521004), ('My_std', 0.025553806029388323), ('Fz_mean', 0.028716162328607124), ('M_mag_min', 0.033829996506917634), ('Fz_energy', 0.039288028198355002), ('AX_max', 0.047572924794469749), ('AX_skew', 0.052394960450023002), ('My_min', 0.062486201048253899), ('Mx_mean', 0.065864926557297046), ('Fx_mean', 0.066114675786432195), ('Mx_energy', 0.071202706408195302), ('Mx_min', 0.075670571854651147)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "             oob_score=True, random_state=None, verbose=0, warm_start=False),\n",
       " StandardScaler(copy=True, with_mean=True, with_std=True))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.do_random_forests_cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running XGB Trees...\n",
      "CTL size: 112 ACT size: 99\n",
      "10-fold CV Acc Mean:  0.937813852814 Scores:  [ 0.90909091  1.          0.85714286  0.95238095  0.95238095  1.\n",
      "  0.95238095  1.          0.9047619   0.85      ]\n",
      "Feature Importances:\n",
      "[('Fz_kurtosis', 0.00031877392755690564), ('Fz_max', 0.00070638610484684641), ('Fy_energy', 0.00091512669487364066), ('Mz_skew', 0.00096581451892246918), ('Fz_entropy', 0.0015701083986986335), ('AX_mean', 0.0020021612139183801), ('Fz_skew', 0.0021904839810011532), ('M_mag_std', 0.0025058610013303324), ('Fx_std', 0.002665888283065711), ('Mz_energy', 0.0028094303546444201), ('Mx_skew', 0.0029516170754920611), ('My_entropy', 0.003283047992613307), ('AX_std', 0.0040924116118364008), ('AX_min', 0.0045409650009984063), ('My_skew', 0.0046612126863766227), ('Fx_energy', 0.0046655372809412806), ('Fy_max', 0.0047820891386740989), ('Fy_kurtosis', 0.0049187449990924226), ('F_mag_kurtosis', 0.0055590514478707472), ('My_mean', 0.0060113228604785395), ('M_mag_entropy', 0.0071213646911134363), ('Mz_kurtosis', 0.0071354551902505399), ('Fz_std', 0.0073166019533030292), ('M_mag_mean', 0.0073291833064262337), ('Fy_min', 0.0078404947010490451), ('Mz_std', 0.0081299767537341729), ('AX_kurtosis', 0.0081824707342688235), ('F_mag_entropy', 0.008245410548830566), ('F_mag_skew', 0.0085064258645854655), ('M_mag_skew', 0.0086565562345952522), ('Fy_std', 0.0086909864092168717), ('My_kurtosis', 0.0088030733680716979), ('Fz_energy', 0.008989412218501169), ('Fx_max', 0.0090641942946830482), ('F_mag_energy', 0.0090732099699898979), ('My_max', 0.009902849798325012), ('Mz_max', 0.0099044438753080558), ('F_mag_mean', 0.010842664802554884), ('Mx_std', 0.010905033718770576), ('F_mag_std', 0.011285746823782812), ('AX_max', 0.011424283065889497), ('Mz_min', 0.012012775076992666), ('Mx_kurtosis', 0.012253950694430558), ('Fx_skew', 0.012576081274106707), ('M_mag_max', 0.014393280006495259), ('Fz_mean', 0.015492947738665467), ('Mz_entropy', 0.01559192083055904), ('My_energy', 0.015787972803609399), ('Fy_mean', 0.015991227184535137), ('M_mag_kurtosis', 0.016148386948636604), ('F_mag_min', 0.016222074385045745), ('Mx_max', 0.016689018156843111), ('Fx_kurtosis', 0.016906921175388879), ('Fx_min', 0.017105289191935477), ('M_mag_min', 0.021422176648798055), ('Mx_mean', 0.021714745216956682), ('M_mag_energy', 0.02245867790180462), ('Fz_min', 0.022741730232482115), ('F_mag_max', 0.023128997545303377), ('Mz_mean', 0.023361107064973206), ('Mx_energy', 0.023913100951305451), ('Mx_min', 0.024322582790954134), ('Fy_skew', 0.024977743540738461), ('Mx_entropy', 0.025224369933471415), ('My_std', 0.025998448432822743), ('Fx_entropy', 0.026835342942038598), ('Fx_mean', 0.028413948746404117), ('AX_skew', 0.042680261184691176), ('Fy_entropy', 0.056365640314409611), ('My_min', 0.064803408189119699)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "               max_depth=3, max_features='sqrt', max_leaf_nodes=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "               presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "               warm_start=False),\n",
       " StandardScaler(copy=True, with_mean=True, with_std=True))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.do_xgb_trees_cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running SVC...\n",
      "CTL size: 112 ACT size: 99\n",
      "10-fold CV Acc Mean:  0.942835497835 Scores:  [ 0.95454545  1.          1.          0.9047619   0.95238095  0.95238095\n",
      "  0.85714286  0.95238095  0.9047619   0.95      ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "   max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " StandardScaler(copy=True, with_mean=True, with_std=True))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.do_svc_cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Neural Network...\n",
      "CTL size: 112 ACT size: 99\n",
      "Step #1, avg. loss: 0.91763\n",
      "Step #101, epoch #50, avg. loss: 0.12606\n",
      "Step #201, epoch #100, avg. loss: 0.02114\n",
      "Step #301, epoch #150, avg. loss: 0.00798\n",
      "Step #401, epoch #200, avg. loss: 0.00435\n",
      "Step #501, epoch #250, avg. loss: 0.00280\n",
      "Step #601, epoch #300, avg. loss: 0.00203\n",
      "Step #701, epoch #350, avg. loss: 0.00155\n",
      "Step #801, epoch #400, avg. loss: 0.00125\n",
      "Step #901, epoch #450, avg. loss: 0.00104\n",
      "Step #1, avg. loss: 0.98098\n",
      "Step #101, epoch #50, avg. loss: 0.12336\n",
      "Step #201, epoch #100, avg. loss: 0.02093\n",
      "Step #301, epoch #150, avg. loss: 0.00796\n",
      "Step #401, epoch #200, avg. loss: 0.00431\n",
      "Step #501, epoch #250, avg. loss: 0.00277\n",
      "Step #601, epoch #300, avg. loss: 0.00200\n",
      "Step #701, epoch #350, avg. loss: 0.00153\n",
      "Step #801, epoch #400, avg. loss: 0.00122\n",
      "Step #901, epoch #450, avg. loss: 0.00101\n",
      "Step #1, avg. loss: 0.93748\n",
      "Step #101, epoch #50, avg. loss: 0.11745\n",
      "Step #201, epoch #100, avg. loss: 0.01891\n",
      "Step #301, epoch #150, avg. loss: 0.00704\n",
      "Step #401, epoch #200, avg. loss: 0.00384\n",
      "Step #501, epoch #250, avg. loss: 0.00249\n",
      "Step #601, epoch #300, avg. loss: 0.00180\n",
      "Step #701, epoch #350, avg. loss: 0.00138\n",
      "Step #801, epoch #400, avg. loss: 0.00111\n",
      "Step #901, epoch #450, avg. loss: 0.00091\n",
      "Step #1, avg. loss: 1.08414\n",
      "Step #101, epoch #50, avg. loss: 0.12319\n",
      "Step #201, epoch #100, avg. loss: 0.02157\n",
      "Step #301, epoch #150, avg. loss: 0.00823\n",
      "Step #401, epoch #200, avg. loss: 0.00441\n",
      "Step #501, epoch #250, avg. loss: 0.00288\n",
      "Step #601, epoch #300, avg. loss: 0.00208\n",
      "Step #701, epoch #350, avg. loss: 0.00157\n",
      "Step #801, epoch #400, avg. loss: 0.00126\n",
      "Step #901, epoch #450, avg. loss: 0.00104\n",
      "Step #1, avg. loss: 1.04673\n",
      "Step #101, epoch #50, avg. loss: 0.12188\n",
      "Step #201, epoch #100, avg. loss: 0.01887\n",
      "Step #301, epoch #150, avg. loss: 0.00718\n",
      "Step #401, epoch #200, avg. loss: 0.00396\n",
      "Step #501, epoch #250, avg. loss: 0.00263\n",
      "Step #601, epoch #300, avg. loss: 0.00191\n",
      "Step #701, epoch #350, avg. loss: 0.00147\n",
      "Step #801, epoch #400, avg. loss: 0.00118\n",
      "Step #901, epoch #450, avg. loss: 0.00098\n",
      "Step #1, avg. loss: 0.96087\n",
      "Step #101, epoch #50, avg. loss: 0.10843\n",
      "Step #201, epoch #100, avg. loss: 0.01394\n",
      "Step #301, epoch #150, avg. loss: 0.00517\n",
      "Step #401, epoch #200, avg. loss: 0.00287\n",
      "Step #501, epoch #250, avg. loss: 0.00189\n",
      "Step #601, epoch #300, avg. loss: 0.00139\n",
      "Step #701, epoch #350, avg. loss: 0.00107\n",
      "Step #801, epoch #400, avg. loss: 0.00087\n",
      "Step #901, epoch #450, avg. loss: 0.00072\n",
      "Step #1, avg. loss: 1.05922\n",
      "Step #101, epoch #50, avg. loss: 0.12632\n",
      "Step #201, epoch #100, avg. loss: 0.02017\n",
      "Step #301, epoch #150, avg. loss: 0.00751\n",
      "Step #401, epoch #200, avg. loss: 0.00408\n",
      "Step #501, epoch #250, avg. loss: 0.00265\n",
      "Step #601, epoch #300, avg. loss: 0.00192\n",
      "Step #701, epoch #350, avg. loss: 0.00148\n",
      "Step #801, epoch #400, avg. loss: 0.00119\n",
      "Step #901, epoch #450, avg. loss: 0.00098\n",
      "Step #1, avg. loss: 0.88835\n",
      "Step #101, epoch #50, avg. loss: 0.12733\n",
      "Step #201, epoch #100, avg. loss: 0.02142\n",
      "Step #301, epoch #150, avg. loss: 0.00793\n",
      "Step #401, epoch #200, avg. loss: 0.00429\n",
      "Step #501, epoch #250, avg. loss: 0.00276\n",
      "Step #601, epoch #300, avg. loss: 0.00199\n",
      "Step #701, epoch #350, avg. loss: 0.00153\n",
      "Step #801, epoch #400, avg. loss: 0.00122\n",
      "Step #901, epoch #450, avg. loss: 0.00101\n",
      "Step #1, avg. loss: 1.09376\n",
      "Step #101, epoch #50, avg. loss: 0.12920\n",
      "Step #201, epoch #100, avg. loss: 0.02053\n",
      "Step #301, epoch #150, avg. loss: 0.00763\n",
      "Step #401, epoch #200, avg. loss: 0.00411\n",
      "Step #501, epoch #250, avg. loss: 0.00269\n",
      "Step #601, epoch #300, avg. loss: 0.00193\n",
      "Step #701, epoch #350, avg. loss: 0.00149\n",
      "Step #801, epoch #400, avg. loss: 0.00120\n",
      "Step #901, epoch #450, avg. loss: 0.00099\n",
      "Step #1, avg. loss: 1.02505\n",
      "Step #101, epoch #50, avg. loss: 0.10961\n",
      "Step #201, epoch #100, avg. loss: 0.01631\n",
      "Step #301, epoch #150, avg. loss: 0.00620\n",
      "Step #401, epoch #200, avg. loss: 0.00340\n",
      "Step #501, epoch #250, avg. loss: 0.00225\n",
      "Step #601, epoch #300, avg. loss: 0.00164\n",
      "Step #701, epoch #350, avg. loss: 0.00127\n",
      "Step #801, epoch #400, avg. loss: 0.00102\n",
      "Step #901, epoch #450, avg. loss: 0.00085\n",
      "10-fold CV Acc Mean:  0.93354978355 Scores:  [0.95454545454545459, 0.95238095238095233, 0.90476190476190477, 0.95238095238095233, 0.95238095238095233, 0.80952380952380953, 0.95238095238095233, 1.0, 1.0, 0.8571428571428571]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorFlowEstimator(batch_size=100, class_weight=None,\n",
       "           continue_training=False, early_stopping_rounds=None,\n",
       "           keep_checkpoint_every_n_hours=10000, learning_rate=0.1,\n",
       "           max_to_keep=5, model_fn=<function relu_dnn at 0x117713938>,\n",
       "           n_classes=2, num_cores=4, optimizer='SGD', steps=1000,\n",
       "           tf_master='', tf_random_seed=42, verbose=1),\n",
       " StandardScaler(copy=True, with_mean=True, with_std=True))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.do_dnn_cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Ensemble Cross Val...\n",
      "CTL size: 112 ACT size: 99\n",
      "Step #1, avg. loss: 1.05668\n",
      "Step #101, epoch #50, avg. loss: 0.11811\n",
      "Step #201, epoch #100, avg. loss: 0.01751\n",
      "Step #301, epoch #150, avg. loss: 0.00633\n",
      "Step #401, epoch #200, avg. loss: 0.00347\n",
      "Step #501, epoch #250, avg. loss: 0.00226\n",
      "Step #601, epoch #300, avg. loss: 0.00164\n",
      "Step #701, epoch #350, avg. loss: 0.00126\n",
      "Step #801, epoch #400, avg. loss: 0.00102\n",
      "Step #901, epoch #450, avg. loss: 0.00084\n",
      "Step #1, avg. loss: 0.95987\n",
      "Step #101, epoch #50, avg. loss: 0.12206\n",
      "Step #201, epoch #100, avg. loss: 0.02041\n",
      "Step #301, epoch #150, avg. loss: 0.00764\n",
      "Step #401, epoch #200, avg. loss: 0.00413\n",
      "Step #501, epoch #250, avg. loss: 0.00269\n",
      "Step #601, epoch #300, avg. loss: 0.00195\n",
      "Step #701, epoch #350, avg. loss: 0.00149\n",
      "Step #801, epoch #400, avg. loss: 0.00120\n",
      "Step #901, epoch #450, avg. loss: 0.00099\n",
      "Step #1, avg. loss: 1.04651\n",
      "Step #101, epoch #50, avg. loss: 0.11284\n",
      "Step #201, epoch #100, avg. loss: 0.01817\n",
      "Step #301, epoch #150, avg. loss: 0.00702\n",
      "Step #401, epoch #200, avg. loss: 0.00388\n",
      "Step #501, epoch #250, avg. loss: 0.00253\n",
      "Step #601, epoch #300, avg. loss: 0.00183\n",
      "Step #701, epoch #350, avg. loss: 0.00141\n",
      "Step #801, epoch #400, avg. loss: 0.00113\n",
      "Step #901, epoch #450, avg. loss: 0.00094\n",
      "Step #1, avg. loss: 0.97654\n",
      "Step #101, epoch #50, avg. loss: 0.10397\n",
      "Step #201, epoch #100, avg. loss: 0.01274\n",
      "Step #301, epoch #150, avg. loss: 0.00487\n",
      "Step #401, epoch #200, avg. loss: 0.00274\n",
      "Step #501, epoch #250, avg. loss: 0.00183\n",
      "Step #601, epoch #300, avg. loss: 0.00135\n",
      "Step #701, epoch #350, avg. loss: 0.00104\n",
      "Step #801, epoch #400, avg. loss: 0.00085\n",
      "Step #901, epoch #450, avg. loss: 0.00071\n",
      "Step #1, avg. loss: 1.01128\n",
      "Step #101, epoch #50, avg. loss: 0.12529\n",
      "Step #201, epoch #100, avg. loss: 0.02090\n",
      "Step #301, epoch #150, avg. loss: 0.00808\n",
      "Step #401, epoch #200, avg. loss: 0.00435\n",
      "Step #501, epoch #250, avg. loss: 0.00283\n",
      "Step #601, epoch #300, avg. loss: 0.00206\n",
      "Step #701, epoch #350, avg. loss: 0.00157\n",
      "Step #801, epoch #400, avg. loss: 0.00126\n",
      "Step #901, epoch #450, avg. loss: 0.00104\n",
      "Step #1, avg. loss: 0.95007\n",
      "Step #101, epoch #50, avg. loss: 0.12869\n",
      "Step #201, epoch #100, avg. loss: 0.02069\n",
      "Step #301, epoch #150, avg. loss: 0.00768\n",
      "Step #401, epoch #200, avg. loss: 0.00411\n",
      "Step #501, epoch #250, avg. loss: 0.00268\n",
      "Step #601, epoch #300, avg. loss: 0.00193\n",
      "Step #701, epoch #350, avg. loss: 0.00148\n",
      "Step #801, epoch #400, avg. loss: 0.00118\n",
      "Step #901, epoch #450, avg. loss: 0.00098\n",
      "Step #1, avg. loss: 0.99385\n",
      "Step #101, epoch #50, avg. loss: 0.11846\n",
      "Step #201, epoch #100, avg. loss: 0.01876\n",
      "Step #301, epoch #150, avg. loss: 0.00701\n",
      "Step #401, epoch #200, avg. loss: 0.00388\n",
      "Step #501, epoch #250, avg. loss: 0.00251\n",
      "Step #601, epoch #300, avg. loss: 0.00184\n",
      "Step #701, epoch #350, avg. loss: 0.00141\n",
      "Step #801, epoch #400, avg. loss: 0.00114\n",
      "Step #901, epoch #450, avg. loss: 0.00095\n",
      "Step #1, avg. loss: 1.02191\n",
      "Step #101, epoch #50, avg. loss: 0.12300\n",
      "Step #201, epoch #100, avg. loss: 0.01981\n",
      "Step #301, epoch #150, avg. loss: 0.00760\n",
      "Step #401, epoch #200, avg. loss: 0.00411\n",
      "Step #501, epoch #250, avg. loss: 0.00270\n",
      "Step #601, epoch #300, avg. loss: 0.00194\n",
      "Step #701, epoch #350, avg. loss: 0.00148\n",
      "Step #801, epoch #400, avg. loss: 0.00119\n",
      "Step #901, epoch #450, avg. loss: 0.00099\n",
      "Step #1, avg. loss: 0.95792\n",
      "Step #101, epoch #50, avg. loss: 0.12662\n",
      "Step #201, epoch #100, avg. loss: 0.01997\n",
      "Step #301, epoch #150, avg. loss: 0.00748\n",
      "Step #401, epoch #200, avg. loss: 0.00400\n",
      "Step #501, epoch #250, avg. loss: 0.00262\n",
      "Step #601, epoch #300, avg. loss: 0.00188\n",
      "Step #701, epoch #350, avg. loss: 0.00145\n",
      "Step #801, epoch #400, avg. loss: 0.00116\n",
      "Step #901, epoch #450, avg. loss: 0.00096\n",
      "Step #1, avg. loss: 0.97343\n",
      "Step #101, epoch #50, avg. loss: 0.13005\n",
      "Step #201, epoch #100, avg. loss: 0.02095\n",
      "Step #301, epoch #150, avg. loss: 0.00775\n",
      "Step #401, epoch #200, avg. loss: 0.00420\n",
      "Step #501, epoch #250, avg. loss: 0.00274\n",
      "Step #601, epoch #300, avg. loss: 0.00196\n",
      "Step #701, epoch #350, avg. loss: 0.00151\n",
      "Step #801, epoch #400, avg. loss: 0.00120\n",
      "Step #901, epoch #450, avg. loss: 0.00100\n",
      "10-fold CV Acc Mean:  0.94329004329 Scores:  [0.90909090909090906, 0.95238095238095233, 0.8571428571428571, 0.8571428571428571, 0.95238095238095233, 1.0, 0.90476190476190477, 1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(VotingClassifier(estimators=[('dnn', TensorFlowEstimator(batch_size=100, class_weight=None,\n",
       "           continue_training=False, early_stopping_rounds=None,\n",
       "           keep_checkpoint_every_n_hours=10000, learning_rate=0.1,\n",
       "           max_to_keep=5, model_fn=<function relu_dnn at 0x117e295f0>,\n",
       "           n_classes=2, num...',\n",
       "   max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False))],\n",
       "          voting='soft', weights=[1, 1, 1, 1]),\n",
       " StandardScaler(copy=True, with_mean=True, with_std=True))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.do_ensemble_cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
